# Synod Module: Phase 0 - Setup

**Inputs:**
- `MODE` - Deliberation mode (review/design/debug/idea/general)
- `PROBLEM` - User's problem statement
- `CLASSIFY_RESULT` - Auto-classification output (when enabled)

**Outputs:**
- `SESSION_ID` - Unique session identifier
- `SESSION_DIR` - Session state directory path
- Model configuration (Gemini/OpenAI settings)
- `meta.json` and `status.json` in session directory

**Cross-references:**
- Called after Step 0.1 in main `synod.md`
- Outputs consumed by `synod-phase1-solver.md`

---

## Step 0.2: Classify Problem Type

**v2.0:** When auto-classification is enabled (`SYNOD_V2_AUTO_CLASSIFY=1`), this step is handled by `synod-classifier.py` and the result is available in `CLASSIFY_RESULT`. Otherwise, analyze the PROBLEM manually:

| Problem Type | Indicators |
|--------------|------------|
| `coding` | Code snippets, function names, syntax, bugs, refactoring |
| `math` | Numbers, equations, algorithms, optimization |
| `creative` | Ideas, brainstorming, naming, design concepts |
| `general` | Questions, explanations, comparisons |

## Step 0.3: Determine Complexity & Round Count (v2.0)

**v2.0:** When dynamic rounds is enabled (`SYNOD_V2_DYNAMIC_ROUNDS=1`), complexity and round count are determined by `synod-classifier.py`. **v2.1:** Thresholds are loaded from `config/synod-modes.yaml` via `synod_config.py`:

```bash
# Load complexity thresholds from config (v2.1)
SIMPLE_MAX=$(python3 "${TOOLS_DIR}/synod_config.py" complexity simple max_score 2>/dev/null || echo "0.5")
MEDIUM_MAX=$(python3 "${TOOLS_DIR}/synod_config.py" complexity medium max_score 2>/dev/null || echo "2.0")
```

**Fallback Reference** (used when config unavailable):

| Complexity | Indicators | Rounds |
|------------|------------|--------|
| `simple` | Single concept, short answer expected, <50 words input | 2 |
| `medium` | Multiple aspects, moderate depth, 50-200 words input | 3 |
| `complex` | System-level, many dependencies, >200 words or multi-file | 4 |

```bash
if [[ "${SYNOD_V2_DYNAMIC_ROUNDS:-1}" == "1" && -n "$CLASSIFY_RESULT" ]]; then
    COMPLEXITY=$(echo "$CLASSIFY_RESULT" | python3 -c "import sys,json; print(json.load(sys.stdin)['complexity'])")
    AUTO_ROUNDS=$(echo "$CLASSIFY_RESULT" | python3 -c "import sys,json; print(json.load(sys.stdin)['rounds'])")
    PROBLEM_TYPE=$(echo "$CLASSIFY_RESULT" | python3 -c "import sys,json; print(json.load(sys.stdin).get('problem_type','general'))")

    echo "[ProblemType] ${PROBLEM_TYPE}" >&2

    # design/idea modes get minimum 3 rounds
    if [[ "$MODE" == "design" || "$MODE" == "idea" ]]; then
        TOTAL_ROUNDS=$(( AUTO_ROUNDS > 3 ? AUTO_ROUNDS : 3 ))
    else
        TOTAL_ROUNDS=$AUTO_ROUNDS
    fi

    echo "[Rounds] Complexity: ${COMPLEXITY} → Rounds: ${TOTAL_ROUNDS}" >&2
fi
```

**Fallback:** If classifier is unavailable or dynamic rounds is disabled, use the static table below.

## Step 0.4: Select Model Configuration

> **Note:** Model execution in Synod uses CLI tools (`$GEMINI_CLI`, `$OPENAI_CLI`) exclusively.
> Do not route model calls through MCP tools (`ask_codex`, `ask_gemini`).

**Setup-Aware Selection:** Check `~/.synod/setup-result.json` (generated by `/synod-setup`) before using static defaults:

```bash
SETUP_FILE="$HOME/.synod/setup-result.json"
if [[ -f "$SETUP_FILE" ]]; then
    echo "[Setup] setup-result.json 발견 - 모델 가용성 적용" >&2

    # Read recommendations from setup
    GEMINI_REC=$(python3 -c "import json; print(json.load(open('$SETUP_FILE')).get('recommendations',{}).get('gemini',''))" 2>/dev/null)
    OPENAI_REC=$(python3 -c "import json; print(json.load(open('$SETUP_FILE')).get('recommendations',{}).get('openai',''))" 2>/dev/null)

    # Read unavailable models (failed or timeout)
    UNAVAILABLE=$(python3 -c "
import json
d = json.load(open('$SETUP_FILE'))
for r in d.get('results', []):
    if r['status'] in ('failed', 'timeout'):
        print(f\"{r['provider']}/{r['model']}\")
" 2>/dev/null)

    # Override mode defaults with setup recommendations
    # Only override if the recommended model is compatible with mode requirements
    SETUP_OVERRIDE=true
else
    SETUP_OVERRIDE=false
fi
```

**v2.1:** Load model configuration from `config/synod-modes.yaml` via `synod_config.py`:

```bash
# Load model config from YAML (v2.1)
GEMINI_MODEL=$(python3 "${TOOLS_DIR}/synod_config.py" modes $MODE models gemini model 2>/dev/null)
GEMINI_THINKING=$(python3 "${TOOLS_DIR}/synod_config.py" modes $MODE models gemini thinking 2>/dev/null)
OPENAI_MODEL=$(python3 "${TOOLS_DIR}/synod_config.py" modes $MODE models openai model 2>/dev/null)
OPENAI_REASONING=$(python3 "${TOOLS_DIR}/synod_config.py" modes $MODE models openai reasoning 2>/dev/null)
BASE_ROUNDS=$(python3 -c "
import sys; sys.path.insert(0,'${TOOLS_DIR}')
from synod_config import get_rounds
print(get_rounds('$MODE')['base'])
" 2>/dev/null)

# Fallback to defaults if config unavailable
GEMINI_MODEL="${GEMINI_MODEL:-flash}"
GEMINI_THINKING="${GEMINI_THINKING:-medium}"
OPENAI_MODEL="${OPENAI_MODEL:-gpt4o}"
OPENAI_REASONING="${OPENAI_REASONING:-}"
BASE_ROUNDS="${BASE_ROUNDS:-3}"
```

**v3.1:** Apply tier-based model override using classifier's tier output:

```bash
# Load tier from classifier result (v3.1)
if [[ -n "$CLASSIFY_RESULT" ]]; then
    TIER=$(echo "$CLASSIFY_RESULT" | python3 -c "import sys,json; print(json.load(sys.stdin).get('tier','standard'))")
else
    TIER="standard"
fi

# Apply tier-based model override (v3.1)
# Tier overrides mode defaults: fast uses cheaper models, deep uses strongest
if [[ "$TIER" != "standard" ]]; then
    TIERED_GEMINI_MODEL=$(python3 -c "
import sys; sys.path.insert(0,'${TOOLS_DIR}')
from synod_config import get_tiered_model_config
c = get_tiered_model_config('$MODE', 'gemini', '$TIER')
print(c.get('model',''))
" 2>/dev/null)
    TIERED_GEMINI_THINKING=$(python3 -c "
import sys; sys.path.insert(0,'${TOOLS_DIR}')
from synod_config import get_tiered_model_config
c = get_tiered_model_config('$MODE', 'gemini', '$TIER')
print(c.get('thinking',''))
" 2>/dev/null)
    TIERED_OPENAI_MODEL=$(python3 -c "
import sys; sys.path.insert(0,'${TOOLS_DIR}')
from synod_config import get_tiered_model_config
c = get_tiered_model_config('$MODE', 'openai', '$TIER')
print(c.get('model',''))
" 2>/dev/null)
    TIERED_OPENAI_REASONING=$(python3 -c "
import sys; sys.path.insert(0,'${TOOLS_DIR}')
from synod_config import get_tiered_model_config
c = get_tiered_model_config('$MODE', 'openai', '$TIER')
print(c.get('reasoning',''))
" 2>/dev/null)

    # Apply overrides if non-empty
    if [[ -n "$TIERED_GEMINI_MODEL" ]]; then
        echo "[Tier] Gemini: ${GEMINI_MODEL} → ${TIERED_GEMINI_MODEL} (tier: ${TIER})" >&2
        GEMINI_MODEL="$TIERED_GEMINI_MODEL"
    fi
    if [[ -n "$TIERED_GEMINI_THINKING" ]]; then
        GEMINI_THINKING="$TIERED_GEMINI_THINKING"
    fi
    if [[ -n "$TIERED_OPENAI_MODEL" ]]; then
        echo "[Tier] OpenAI: ${OPENAI_MODEL} → ${TIERED_OPENAI_MODEL} (tier: ${TIER})" >&2
        OPENAI_MODEL="$TIERED_OPENAI_MODEL"
    fi
    if [[ -n "$TIERED_OPENAI_REASONING" && "$TIERED_OPENAI_REASONING" != "None" ]]; then
        OPENAI_REASONING="$TIERED_OPENAI_REASONING"
    fi
fi
```

**v3.2:** Apply problem_type-aware model adjustments. These are soft hints that refine model selection based on the nature of the problem (coding, math, creative). Existing fallbacks remain intact.

```bash
# Apply problem_type-aware adjustments (v3.2)
# PROBLEM_TYPE is extracted in Step 0.3 from CLASSIFY_RESULT
if [[ -n "$PROBLEM_TYPE" && "$PROBLEM_TYPE" != "general" ]]; then
    case "$PROBLEM_TYPE" in
        coding)
            # Coding problems benefit from higher thinking in general mode
            if [[ "$MODE" == "general" ]]; then
                echo "[ProblemType] coding + general → thinking: high" >&2
                GEMINI_THINKING="high"
            fi
            ;;
        math)
            # Math problems benefit from reasoning models (o3 over gpt4o)
            if [[ "$OPENAI_MODEL" == "gpt4o" ]]; then
                echo "[ProblemType] math → OpenAI: gpt4o → o3" >&2
                OPENAI_MODEL="o3"
            fi
            ;;
        creative)
            # Creative problems benefit from pro model (pro over flash)
            if [[ "$GEMINI_MODEL" == "flash" ]]; then
                echo "[ProblemType] creative → Gemini: flash → pro" >&2
                GEMINI_MODEL="pro"
            fi
            ;;
    esac
fi
```

Select configurations (overridden by setup results when available, **fallback reference** when config unavailable):

| Mode | Gemini Model | Gemini Thinking | OpenAI Model | OpenAI Reasoning | Base Rounds | Dynamic |
|------|--------------|-----------------|--------------|------------------|-------------|---------|
| `review` | flash | high | o3 | medium | 3 | Yes (2-4) |
| `design` | pro | high | o3 | high | 4 | Yes (3-4) |
| `debug` | flash | high | o3 | high | 3 | Yes (2-4) |
| `idea` | pro | high | gpt4o | - | 4 | Yes (3-4) |
| `general` | flash | medium | gpt4o | - | 3 | Yes (2-4) |

**Setup Override Logic:**

```bash
if [[ "$SETUP_OVERRIDE" == "true" ]]; then
    # Skip unavailable models
    if echo "$UNAVAILABLE" | grep -q "gemini/${GEMINI_MODEL}"; then
        if [[ -n "$GEMINI_REC" ]]; then
            echo "[Setup] Gemini ${GEMINI_MODEL} 사용 불가 → ${GEMINI_REC}로 대체" >&2
            GEMINI_MODEL="$GEMINI_REC"
        else
            echo "[Setup] Gemini 사용 불가 - Claude + OpenAI만 사용" >&2
            GEMINI_MODEL=""
        fi
    fi

    if echo "$UNAVAILABLE" | grep -q "openai/${OPENAI_MODEL}"; then
        if [[ -n "$OPENAI_REC" ]]; then
            echo "[Setup] OpenAI ${OPENAI_MODEL} 사용 불가 → ${OPENAI_REC}로 대체" >&2
            OPENAI_MODEL="$OPENAI_REC"
        else
            echo "[Setup] OpenAI 사용 불가 - Claude + Gemini만 사용" >&2
            OPENAI_MODEL=""
        fi
    fi
fi
```

**Note:** When `SYNOD_V2_DYNAMIC_ROUNDS=1`, round count is determined by complexity analysis from Step 0.3. The "Base Rounds" column is the fallback when dynamic rounds is disabled.

**Note:** Run `/synod-setup` to generate `~/.synod/setup-result.json`. Without it, the static table above is used as-is.

## Step 0.4b: Extended Model Options (Optional)

Users can configure alternative models via environment variables or flags:

| Provider | CLI | Models | Best For | Env Var |
|----------|-----|--------|----------|---------|
| DeepSeek | deepseek-cli | chat, reasoner (R1) | 추론, 수학 | DEEPSEEK_API_KEY |
| Groq | groq-cli | 8b, 70b, mixtral | 초고속 응답 | GROQ_API_KEY |
| Grok | grok-cli | fast, grok4, mini, vision | 2M context | XAI_API_KEY |
| Mistral | mistral-cli | large, medium, small, codestral | 코드, 유럽 | MISTRAL_API_KEY |

**Note:** Default configuration uses Gemini + OpenAI. Extended models require additional API keys.

## Step 0.4c: Creativity Configuration

### Model Creativity Settings

| Model | Creativity Level | Flag | Notes |
|-------|-----------------|------|-------|
| Gemini (Solver/Defense) | high | `--thinking high` | 창의성 + 정확성 균형 |
| Gemini (Critic) | medium | `--thinking medium` | 분석적 평가 |
| OpenAI o3 | high | `--reasoning high` | 심층 추론 |
| OpenAI gpt4o | medium | `--reasoning medium` | 균형잡힌 응답 |

**NOTE: CLI Parameter Mapping**

각 CLI는 Temperature 대신 다른 창의성 파라미터를 사용합니다:
- temperature: 1.0 (고정)
- top_p: 1.0 (고정)

**대체 제어**: `--reasoning` 플래그 사용 (low/medium/high)

### o3 Reasoning Effort by Mode

| Mode | reasoning_effort | 설명 |
|------|------------------|------|
| review | medium | 균형 잡힌 분석 |
| design | high | 심층 아키텍처 추론 |
| debug | high | 근본 원인 분석 |
| idea | medium | 창의적 탐색 |
| general | low | 빠른 응답 |

## Step 0.5: Generate Session ID & Create State Directory

```bash
SESSION_ID="synod-$(date +%Y%m%d-%H%M%S)-$(openssl rand -hex 3)"
SESSION_DIR=".omc/synod/${SESSION_ID}"
mkdir -p "${SESSION_DIR}/round-1-solver"
mkdir -p "${SESSION_DIR}/round-2-critic"
mkdir -p "${SESSION_DIR}/round-3-defense"

# Initialize progress display (v2.1)
PROGRESS_FIFO="${SESSION_DIR}/progress-fifo"
mkfifo "$PROGRESS_FIFO" 2>/dev/null
python3 "${TOOLS_DIR}/synod_progress.py" < "$PROGRESS_FIFO" &
PROGRESS_PID=$!

# Progress helper function
synod_progress() { echo "$1" > "$PROGRESS_FIFO" 2>/dev/null; }

# Emit setup phase start
synod_progress '{"event":"phase_start","phase":0,"name":"Setup"}'
```

**Progress Cleanup:** On session end or error:
```bash
synod_progress '{"event":"phase_end","phase":4}'
kill $PROGRESS_PID 2>/dev/null; rm -f "$PROGRESS_FIFO"
```

## Step 0.6: Initialize Session State

Write `${SESSION_DIR}/meta.json`:
```json
{
  "session_id": "{SESSION_ID}",
  "created_at": "{ISO_TIMESTAMP}",
  "mode": "{MODE}",
  "problem_type": "{coding|math|creative|general}",
  "complexity": "{simple|medium|complex}",
  "problem_summary": "{First 200 chars of PROBLEM}",
  "model_config": {
    "gemini": {"model": "{flash|pro}", "thinking": "{medium|high}"},
    "openai": {"model": "{o3|gpt4o}", "reasoning": "{medium|high|null}"}
  },
  "total_rounds": {3|4}
}
```

Write initial `${SESSION_DIR}/status.json`:
```json
{
  "current_round": 0,
  "round_status": {"0": "in_progress", "1": "pending", "2": "pending", "3": "pending", "4": "pending"},
  "last_updated": "{ISO_TIMESTAMP}",
  "can_resume": true,
  "resume_point": "phase-0-classification"
}
```

**Announce to user:**
```
[Synod v3.1] 세션: {SESSION_ID}
모드: {MODE} (auto-classified, confidence: {CLASSIFY_CONFIDENCE}) | 티어: {TIER} | 복잡도: {complexity}
모델: Gemini {model} ({thinking}) + OpenAI {model} ({reasoning})
라운드: {total_rounds} {dynamic: true/false}
Setup: {SETUP_OVERRIDE ? "적용됨 (setup-result.json)" : "미설정 - /synod-setup 권장"}
```

**Note:** When mode was explicitly specified (legacy), show `(explicit, deprecated)` instead of confidence.
**Note:** When setup overrides are active, show which models were replaced due to unavailability.

Update status.json: `"round_status": {"0": "complete", ...}`

**Next Phase:** Proceed to Phase 1 (see `synod-phase1-solver.md`)
